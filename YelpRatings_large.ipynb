{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14302,
     "status": "ok",
     "timestamp": 1607372456602,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "SlavtS_z1Nji",
    "outputId": "561b3597-b1cd-4613-fe74-b842569a64de"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Install java\n",
    "# ! apt-get update -qq\n",
    "# ! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "# ! java -version\n",
    "\n",
    "# # Install pyspark\n",
    "# ! pip install --ignore-installed -q pyspark==2.4.4\n",
    "# ! pip install --ignore-installed -q spark-nlp==2.6.3-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18656,
     "status": "ok",
     "timestamp": 1607372489578,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "0M_HL-s12jSo",
    "outputId": "d2bfd28d-9ca8-4aaa-81f2-57797b94a7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 2.6.4\n",
      "Apache Spark version: 2.4.4\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# params =>> gpu=False, spark23=False (start with spark 2.3)\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1607373272112,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "gNaZxuzn5RF3",
    "outputId": "568a4c81-bf66-4204-a924-c42955e80e48"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = '/content/drive/My Drive/CS657/project/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1607373155475,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "12fOOa3859Ja"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import UniversalSentenceEncoder, SentimentDLModel\n",
    "from sparknlp.pretrained import PretrainedPipeline \n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import  pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vQF4Y_sO6LK4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_imdb download started this may take some time.\n",
      "Approximate size to download 12.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "#custom pipeline with pre-trained models\n",
    "\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "# other pre-trained sentiment classification model: sentimentdl_use_twitter\n",
    "# the classes/labels/categories are in category column\n",
    "sentimentdl = SentimentDLModel.pretrained(name=\"sentimentdl_use_imdb\", lang=\"en\")\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"sentiment\")\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_57db2e18c1a6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model = pipeline.fit([]) # already trained\n",
    "pipeline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120005,
     "status": "ok",
     "timestamp": 1607382206576,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "e4Yle4Or3Y9r",
    "outputId": "87c67d86-7ba5-4dc8-e6a8-ad20b784da15"
   },
   "outputs": [],
   "source": [
    "# pipeline = PretrainedPipeline('analyze_sentimentdl_use_imdb', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_id: string, cool: bigint, funny: bigint, review_id: string, stars: double, text: string, useful: bigint, user_id: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yelp_review = spark.read.json(path+'/review.json')\n",
    "yelp_review = spark.read.json('data/yelp_academic_dataset_review.json')\n",
    "yelp_review = yelp_review.drop('date')\n",
    "\n",
    "yelp_review, _ = yelp_review.randomSplit(weights=[0.01, 0.99], seed=1) \n",
    "_.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_id: string, cool: bigint, funny: bigint, review_id: string, stars: double, text: string, useful: bigint, user_id: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to get sentiment for all data (train and test)\n",
    "# yelp_review_annotated = pipeline.annotate(yelp_review, 'text')\n",
    "yelp_review_annotated = pipeline_model.transform(yelp_review)\n",
    "yelp_review.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1607382207460,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "8l1rNtBr1SRY"
   },
   "outputs": [],
   "source": [
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_thresh', yelp_review_annotated.stars - 2.5)\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_thresh_abs',F.abs(yelp_review_annotated.stars_thresh))\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_sent', yelp_review_annotated.stars_thresh / yelp_review_annotated.stars_thresh_abs)\\\n",
    "                                 .drop('stars_thresh_abs', 'stars_thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1607382207461,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "tdwvwFg34Tgy"
   },
   "outputs": [],
   "source": [
    "def sent(r):\n",
    "    meta = r[0][4]\n",
    "    return float(meta['positive']) - float(meta['negative'])\n",
    "\n",
    "sent_udf = F.udf(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1607382207461,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "CR-sXBOP4UIA"
   },
   "outputs": [],
   "source": [
    "yelp_review_annotated = yelp_review_annotated.withColumn('sent_to_num', sent_udf(yelp_review_annotated.sentiment))\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('sent_to_num', yelp_review_annotated.sent_to_num.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 61489,
     "status": "ok",
     "timestamp": 1607382268102,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "kJr1bpBq4dwJ"
   },
   "outputs": [],
   "source": [
    "# yelp_user = spark.read.json(path+'/user.json')\n",
    "yelp_user = spark.read.json('data/yelp_academic_dataset_user.json')\n",
    "\n",
    "yelp_user = yelp_user.select('user_Id', 'review_count', 'average_stars', 'useful', 'fans')\n",
    "\n",
    "#yelp_user\n",
    "yelp_review_sents = yelp_review_annotated.select('stars', 'user_Id', 'sent_to_num', 'useful', 'funny' , 'cool')\n",
    "yelp_review_annotated.unpersist()\n",
    "\n",
    "#yelp_review_sents\n",
    "reviews_j = yelp_review_sents.join(yelp_user, yelp_review_sents.user_Id == yelp_user.user_Id)\n",
    "\n",
    "yelp_user.unpersist()\n",
    "yelp_review_sents.unpersist()\n",
    "\n",
    "reviews_j = reviews_j.drop('user_Id') # we don't need user_Id after this\n",
    "reviews_j = reviews_j.toDF('stars', 'sent_to_num', 'useful_review', 'funny', 'cool', 'user_review_count', 'user_average_stars', 'user_useful', 'user_fans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 61484,
     "status": "ok",
     "timestamp": 1607382268104,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "VA8L0YZ38-IH"
   },
   "outputs": [],
   "source": [
    "#assemble all features together into one vector\n",
    "assembler = VectorAssembler().setInputCols(['sent_to_num', 'useful_review', 'funny', 'cool', 'user_review_count', 'user_average_stars', 'user_useful', 'user_fans']).setOutputCol(\"features\")\n",
    "\n",
    "#transform train, test sets: (stars, [f1, f2, f3, ..., fn])    \n",
    "inputDF = assembler.transform(reviews_j).select(\"stars\", \"features\")\n",
    "\n",
    "reviews_j.unpersist()\n",
    "#split into train and test sets\n",
    "train, test = inputDF.randomSplit(weights=[0.75, 0.25], seed=1) \n",
    "\n",
    "#split train into development and validation\n",
    "development, validation = train.randomSplit(weights=[0.75, 0.25], seed=1) \n",
    "\n",
    "#use development set to train network, validation set to test network to obtain optimal parameters\n",
    "#retrain network on train set with optimal parameters\n",
    "#test network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ALLhizVR9U0j"
   },
   "outputs": [],
   "source": [
    "#development, validation sets used to find optimal parameters\n",
    "#once optimal parameters are found, retrain network on train set\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 8 (features), one intermediate of size 12\n",
    "# and output of size 6 (classes)\n",
    "layers = [8, 12, 6]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=40, layers=layers, \n",
    "                                         blockSize=128, seed=1234, \n",
    "                                         labelCol='stars', stepSize=0.1)\n",
    "\n",
    "# train the model with development set\n",
    "model = trainer.fit(development)\n",
    "\n",
    "# compute accuracy on the validation set\n",
    "result = model.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "F8BljuVpFGix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Validation Set: 1.5391870302580755\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = result.select(\"prediction\", \"stars\")\n",
    "# result.unpersist()\n",
    "\n",
    "evlauator_rmse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"rmse\")\n",
    "rmse = evlauator_rmse.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"RMSE on Validation Set: \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on Validation Set: 0.917320739656778\n"
     ]
    }
   ],
   "source": [
    "# I'm using only RMSE for validation\n",
    "evlauator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"mae\")\n",
    "mae = evlauator_mae.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"MAE on Validation Set: \"+str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxIter=40, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4109812827756614\n",
    "# MAE on Validation Set: 0.814901367388652\n",
    "# ^ Last Exp with maxIter \n",
    "\n",
    "# maxIter=80, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.41099998082853\n",
    "# MAE on Validation Set: 0.815022064679219\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 4, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.5410209010637315\n",
    "# MAE on Validation Set: 0.9124236252545825\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.5674471918547126\n",
    "# MAE on Validation Set: 0.9429735234215886\n",
    "\n",
    "# maxIter=40, layers=[8, 18, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.420025700678034\n",
    "# MAE on Validation Set: 0.815443627144308\n",
    "# ^ Exp with layers (increased maxIter cause of increased complexity)\n",
    "\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.2, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.53800977406008\n",
    "# MAE on Validation Set: 0.918837407325199\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.01, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4889757553339852\n",
    "# MAE on Validation Set: 0.8795244799782438\n",
    "# ^ Exp with stepSize\n",
    "\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4886020026926277\n",
    "# MAE on Validation Set: 0.8787903477908067\n",
    "# ^ Exp with maxIter\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4992918469644249\n",
    "# MAE on Validation Set: 0.8730931519305250\n",
    "\n",
    "# maxIter=200, layers=[8, 6, 6], stepSize=0.1, solver='gd'\n",
    "# RMSE on Validation Set: 1.8845096442689286\n",
    "# MAE on Validation Set: 1.1528520453096466\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 6], stepSize=0.1, solver='gd'\n",
    "# RMSE on Validation Set: 1.955525563079031\n",
    "# MAE on Validation Set: 1.2077877931603328\n",
    "# ^ Exp with solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "44Y5SBL4aUJ_"
   },
   "outputs": [],
   "source": [
    "#retrain network with optimal parameters on the train set\n",
    "#test network on test set\n",
    "\n",
    "layers = [8, 12, 6]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=40, layers=layers, \n",
    "                                         blockSize=128, seed=1234, \n",
    "                                         labelCol='stars', stepSize=0.1)\n",
    "\n",
    "# train the model with full train set\n",
    "model = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Test Set: 1.5572038036260107\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = result.select(\"prediction\", \"stars\")\n",
    "result.unpersist()\n",
    "\n",
    "evlauator_rmse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"rmse\")\n",
    "rmse = evlauator_rmse.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"RMSE on Test Set: \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on Test Set: 0.9299614788133473\n"
     ]
    }
   ],
   "source": [
    "# I'm using only RMSE for validation\n",
    "evlauator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"mae\")\n",
    "mae = evlauator_mae.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"MAE on Test Set: \"+str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxIter=40, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6bm13S4aJozdXBMStgeJJ",
   "collapsed_sections": [],
   "name": "YelpRatings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
