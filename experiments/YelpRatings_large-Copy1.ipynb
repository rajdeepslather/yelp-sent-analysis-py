{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14302,
     "status": "ok",
     "timestamp": 1607372456602,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "SlavtS_z1Nji",
    "outputId": "561b3597-b1cd-4613-fe74-b842569a64de"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Install java\n",
    "# ! apt-get update -qq\n",
    "# ! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "# ! java -version\n",
    "\n",
    "# # Install pyspark\n",
    "# ! pip install --ignore-installed -q pyspark==2.4.4\n",
    "# ! pip install --ignore-installed -q spark-nlp==2.6.3-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18656,
     "status": "ok",
     "timestamp": 1607372489578,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "0M_HL-s12jSo",
    "outputId": "d2bfd28d-9ca8-4aaa-81f2-57797b94a7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 2.6.4\n",
      "Apache Spark version: 2.4.4\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# params =>> gpu=False, spark23=False (start with spark 2.3)\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1607373272112,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "gNaZxuzn5RF3",
    "outputId": "568a4c81-bf66-4204-a924-c42955e80e48"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = '/content/drive/My Drive/CS657/project/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1607373155475,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "12fOOa3859Ja"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import UniversalSentenceEncoder, SentimentDLModel\n",
    "from sparknlp.pretrained import PretrainedPipeline \n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import  pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vQF4Y_sO6LK4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_imdb download started this may take some time.\n",
      "Approximate size to download 12.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "#custom pipeline with pre-trained models\n",
    "\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "# other pre-trained sentiment classification model: sentimentdl_use_twitter\n",
    "# the classes/labels/categories are in category column\n",
    "sentimentdl = SentimentDLModel.pretrained(name=\"sentimentdl_use_imdb\", lang=\"en\")\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"sentiment\")\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_1d72070dbdf8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model = pipeline.fit([]) # already trained\n",
    "pipeline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120005,
     "status": "ok",
     "timestamp": 1607382206576,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "e4Yle4Or3Y9r",
    "outputId": "87c67d86-7ba5-4dc8-e6a8-ad20b784da15"
   },
   "outputs": [],
   "source": [
    "# pipeline = PretrainedPipeline('analyze_sentimentdl_use_imdb', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_id: string, cool: bigint, funny: bigint, review_id: string, stars: double, text: string, useful: bigint, user_id: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yelp_review = spark.read.json(path+'/review.json')\n",
    "yelp_review = spark.read.json('data/yelp_academic_dataset_review.json')\n",
    "yelp_review = yelp_review.drop('date')\n",
    "\n",
    "yelp_review, _ = yelp_review.randomSplit(weights=[0.01, 0.99], seed=1) \n",
    "_.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_id: string, cool: bigint, funny: bigint, review_id: string, stars: double, text: string, useful: bigint, user_id: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to get sentiment for all data (train and test)\n",
    "# yelp_review_annotated = pipeline.annotate(yelp_review, 'text')\n",
    "yelp_review_annotated = pipeline_model.transform(yelp_review)\n",
    "yelp_review.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1607382207460,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "8l1rNtBr1SRY"
   },
   "outputs": [],
   "source": [
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_thresh', yelp_review_annotated.stars - 2.5)\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_thresh_abs',F.abs(yelp_review_annotated.stars_thresh))\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('stars_sent', yelp_review_annotated.stars_thresh / yelp_review_annotated.stars_thresh_abs)\\\n",
    "                                 .drop('stars_thresh_abs', 'stars_thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1607382207461,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "tdwvwFg34Tgy"
   },
   "outputs": [],
   "source": [
    "def sent(r):\n",
    "    meta = r[0][4]\n",
    "    return float(meta['positive']) - float(meta['negative'])\n",
    "\n",
    "sent_udf = F.udf(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1607382207461,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "CR-sXBOP4UIA"
   },
   "outputs": [],
   "source": [
    "yelp_review_annotated = yelp_review_annotated.withColumn('sent_to_num', sent_udf(yelp_review_annotated.sentiment))\n",
    "yelp_review_annotated = yelp_review_annotated.withColumn('sent_to_num', yelp_review_annotated.sent_to_num.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 61489,
     "status": "ok",
     "timestamp": 1607382268102,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "kJr1bpBq4dwJ"
   },
   "outputs": [],
   "source": [
    "# yelp_user = spark.read.json(path+'/user.json')\n",
    "yelp_user = spark.read.json('data/yelp_academic_dataset_user.json')\n",
    "\n",
    "yelp_user = yelp_user.select('user_Id', 'review_count', 'average_stars', 'useful', 'fans')\n",
    "\n",
    "\n",
    "yelp_review_sents = yelp_review_annotated.select('stars', 'user_id', 'text', 'sent_to_num', 'useful', 'funny' , 'cool')\n",
    "reviews_j = yelp_review_sents.join(yelp_user, yelp_review_sents.user_id == yelp_user.user_Id)\n",
    "reviews_j = reviews_j.drop('user_Id')\n",
    "reviews_j = reviews_j.toDF('stars', 'text', 'sent_to_num', 'useful_review', 'funny', 'cool', 'user_review_count', 'user_average_stars', 'user_useful', 'user_fans')\n",
    "\n",
    "\n",
    "#yelp_user\n",
    "# yelp_review_sents = yelp_review_annotated.select('stars', 'user_Id', 'sent_to_num', 'useful', 'funny' , 'cool')\n",
    "# yelp_review_annotated.unpersist()\n",
    "# \n",
    "#yelp_review_sents\n",
    "# reviews_j = yelp_review_sents.join(yelp_user, yelp_review_sents.user_Id == yelp_user.user_Id)\n",
    "# \n",
    "# yelp_user.unpersist()\n",
    "# yelp_review_sents.unpersist()\n",
    "# \n",
    "# reviews_j = reviews_j.drop('user_Id') # we don't need user_Id after this\n",
    "\n",
    "# reviews_j = reviews_j.toDF('stars', 'sent_to_num', 'useful_review', 'funny', 'cool', 'user_review_count', 'user_average_stars', 'user_useful', 'user_fans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revies_l = reviews_j.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stars=3.0, text=\"That chicken tortilla soup is absolutely delicious.  Could be I am a sucker for fresh chunks of avocado.  No, the soup would have even been delicious without it.\\n\\nThe rest of the meal was fine, and filling.  The drinks were reasonably priced.  The restaurant itself is nice... pretty decor.  Nice amenities in the ladies' room, I love the scope with little disposable cups.  Our server did his job adequately.\\n\\nOverall, nothing to complain about, but nothing outstanding aside from that yummy soup.\", sent_to_num=0.99999929192572, useful_review=1, funny=0, cool=1, user_review_count=699, user_average_stars=4.1, user_useful=3697, user_fans=104),\n",
       " Row(stars=4.0, text='Solid place to go for dinner! Great for sharing. I really liked the fried brie, it was my favourite of the evening. Really fun environment to have dinner with friends!', sent_to_num=1.0, useful_review=1, funny=0, cool=0, user_review_count=27, user_average_stars=3.56, user_useful=5, user_fans=0),\n",
       " Row(stars=4.0, text='Very good burgers.  Fries are great as well.  Its located right of the entrance at Aria.  They have dinner and lunch specials.  Burger, fries, and beer for 20 bucks.  Not the best price but good for an expensive vegas. :)', sent_to_num=0.9999999999999998, useful_review=0, funny=0, cool=0, user_review_count=17, user_average_stars=4.61, user_useful=4, user_fans=0),\n",
       " Row(stars=2.0, text='Rude service and gross coffee, as for the bagels... I\\'m a New Yorker, so these bagel-shaped bread things being called \"bagels\" are laughable to me. Also, why are they charging an arm and a leg for basic bagels + eggs, things that are supposed to be cheap?? No, thanks.', sent_to_num=-0.9999999999999989, useful_review=0, funny=0, cool=0, user_review_count=100, user_average_stars=3.71, user_useful=84, user_fans=0),\n",
       " Row(stars=3.0, text=\"The curry tastes good but a bit salty. Given the reasonable price I will come back if I'm craving for Thai curry.\", sent_to_num=0.99999996133049, useful_review=0, funny=0, cool=0, user_review_count=81, user_average_stars=4.55, user_useful=17, user_fans=1),\n",
       " Row(stars=2.0, text=\"The atmosphere, the service and the variety of food is great. Several things we tried were cold and didn't taste fresh. The lobster and the prime rib were both overcooked. \\n\\nOverall, the service and the atmosphere doesn't add enough value to justify the over priced food. Fewer hot, fresh, well prepared food items would at least make up for the astronomically priced subpar choices we had today.\", sent_to_num=0.9999470474600001, useful_review=0, funny=0, cool=0, user_review_count=10, user_average_stars=1.5, user_useful=9, user_fans=0),\n",
       " Row(stars=5.0, text=\"Best place in town! I always get the Greek Salad and it's by far my favorite! The people here are friendly.\", sent_to_num=1.0, useful_review=0, funny=0, cool=0, user_review_count=16, user_average_stars=4.59, user_useful=1, user_fans=0),\n",
       " Row(stars=5.0, text='I did not expected that to be so delicious. Fattening with the whip cream on the English muffin, but yummy.', sent_to_num=0.9999968888505, useful_review=0, funny=0, cool=0, user_review_count=32, user_average_stars=3.53, user_useful=14, user_fans=2),\n",
       " Row(stars=4.0, text=\"I wanted to look for an all you can eat sushi that's downtown. For 25.99 dinner on a weekend, this was relatively better value than other ayce (particularly the ones on dundas). They have a smaller selection of sashimi and sushi compared to others, but it the fish to rice ratio is much more reasonable. As well, they also have a bigger selection of hot food and dim sum which I appreciate. \\n\\nService was OK, they were very attentive in removing empty plates and filling water. \\n\\nThe restaurant was a lot bigger than expected, bathrooms are down the stairs but clean.\", sent_to_num=0.9999999999295691, useful_review=0, funny=0, cool=0, user_review_count=32, user_average_stars=3.53, user_useful=14, user_fans=2),\n",
       " Row(stars=5.0, text=\"Four years later, I'm back!  Felt almost like a pilgrimage back to burrito heaven or something.  Nothing but joy filled my body knowing I'd be coming here again after traveling across the pacific ocean and through miles and miles of cactus filled desert. \\n\\nVisiting AZ for a wedding so my girlfriend and I was here for a few days so Amados was definitely on our hit list!  \\n\\nOh how I wish Hawaii had late night Mexican spots like you.  This visit made me realize just how important places like you are in my life.  \\n\\nOf the four nights in AZ, we ate here three times.  Such quality burritos we just don't see in Hawaii.  And these burritos were no slouch either...these things came packed with carne asada....and for only 6 dollar-ish!  That same burrito would cost 10+ here. \\n\\nTil next time, Amados.  Sigh.\", sent_to_num=0.9999999999999991, useful_review=4, funny=2, cool=5, user_review_count=167, user_average_stars=4.29, user_useful=747, user_fans=26)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revies_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('archive/document_parses/pmc_preprocessed/' + file.split('.')[0] + '.txt', 'w') as fobject:\n",
    "    for line in text.collect():\n",
    "        fobject.write(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 61484,
     "status": "ok",
     "timestamp": 1607382268104,
     "user": {
      "displayName": "stuti polra",
      "photoUrl": "https://lh4.googleusercontent.com/-NGGzbrcewq4/AAAAAAAAAAI/AAAAAAAAAQQ/89dHzfUdYEQ/s64/photo.jpg",
      "userId": "12712467852153144632"
     },
     "user_tz": 300
    },
    "id": "VA8L0YZ38-IH"
   },
   "outputs": [],
   "source": [
    "#assemble all features together into one vector\n",
    "assembler = VectorAssembler().setInputCols(['sent_to_num', 'useful_review', 'funny', 'cool', 'user_review_count', 'user_average_stars', 'user_useful', 'user_fans']).setOutputCol(\"features\")\n",
    "\n",
    "#transform train, test sets: (stars, [f1, f2, f3, ..., fn])    \n",
    "inputDF = assembler.transform(reviews_j).select(\"stars\", \"features\")\n",
    "\n",
    "reviews_j.unpersist()\n",
    "#split into train and test sets\n",
    "train, test = inputDF.randomSplit(weights=[0.75, 0.25], seed=1) \n",
    "\n",
    "#split train into development and validation\n",
    "development, validation = train.randomSplit(weights=[0.75, 0.25], seed=1) \n",
    "\n",
    "#use development set to train network, validation set to test network to obtain optimal parameters\n",
    "#retrain network on train set with optimal parameters\n",
    "#test network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ALLhizVR9U0j"
   },
   "outputs": [],
   "source": [
    "#development, validation sets used to find optimal parameters\n",
    "#once optimal parameters are found, retrain network on train set\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 8 (features), one intermediate of size 12\n",
    "# and output of size 6 (classes)\n",
    "layers = [8, 12, 6]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=40, layers=layers, \n",
    "                                         blockSize=128, seed=1234, \n",
    "                                         labelCol='stars', stepSize=0.1)\n",
    "\n",
    "# train the model with development set\n",
    "model = trainer.fit(development)\n",
    "\n",
    "# compute accuracy on the validation set\n",
    "result = model.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|stars|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1.0|(8,[0,4,5],[0.999...|[-4.9477546997950...|[4.21532992454869...|       5.0|\n",
      "|  1.0|(8,[0,4,5,6],[0.7...|[-4.8580272660170...|[6.22398820739990...|       5.0|\n",
      "|  1.0|[-0.9999999996548...|[-3.4707067683792...|[0.00221091502677...|       1.0|\n",
      "|  1.0|[-0.9999999917136...|[-3.7009570928904...|[0.00185842102586...|       1.0|\n",
      "|  1.0|[-0.9999986165866...|[-3.2273399284754...|[0.00173986909326...|       1.0|\n",
      "|  1.0|[-0.99997406515,1...|[-4.3461684575545...|[0.00130698949786...|       1.0|\n",
      "|  1.0|[0.9999912230217,...|[-4.6149090107150...|[9.20932669909874...|       5.0|\n",
      "|  1.0|[0.99999999987090...|[-4.7714632591789...|[7.17590052660026...|       5.0|\n",
      "|  2.0|(8,[0,4,5],[-0.99...|[-4.2600879723223...|[0.00111076902003...|       1.0|\n",
      "|  2.0|(8,[0,4,5,6],[-0....|[-4.6299625912300...|[0.00107922501503...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8BljuVpFGix"
   },
   "outputs": [],
   "source": [
    "predictionAndLabels = result.select(\"prediction\", \"stars\")\n",
    "# result.unpersist()\n",
    "\n",
    "evlauator_rmse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"rmse\")\n",
    "rmse = evlauator_rmse.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"RMSE on Validation Set: \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using only RMSE for validation\n",
    "evlauator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"mae\")\n",
    "mae = evlauator_mae.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"MAE on Validation Set: \"+str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxIter=40, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4109812827756614\n",
    "# MAE on Validation Set: 0.814901367388652\n",
    "# ^ Last Exp with maxIter \n",
    "\n",
    "# maxIter=80, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.41099998082853\n",
    "# MAE on Validation Set: 0.813022064679219\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 4, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.5410209010637315\n",
    "# MAE on Validation Set: 0.9124236252545825\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 12, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.5674471918547126\n",
    "# MAE on Validation Set: 0.9429735234215886\n",
    "\n",
    "# maxIter=40, layers=[8, 18, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.420025700678034\n",
    "# MAE on Validation Set: 0.815443627144308\n",
    "# ^ Exp with layers (increased maxIter cause of increased complexity)\n",
    "\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.2, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.53800977406008\n",
    "# MAE on Validation Set: 0.918837407325199\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.01, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4889757553339852\n",
    "# MAE on Validation Set: 0.8795244799782438\n",
    "# ^ Exp with stepSize\n",
    "\n",
    "\n",
    "# maxIter=40, layers=[8, 6, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4886020026926277\n",
    "# MAE on Validation Set: 0.8787903477908067\n",
    "# ^ Exp with maxIter\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 6], stepSize=0.1, solver='l-bfgs'\n",
    "# RMSE on Validation Set: 1.4992918469644249\n",
    "# MAE on Validation Set: 0.8730931519305250\n",
    "\n",
    "# maxIter=200, layers=[8, 6, 6], stepSize=0.1, solver='gd'\n",
    "# RMSE on Validation Set: 1.8845096442689286\n",
    "# MAE on Validation Set: 1.1528520453096466\n",
    "\n",
    "# maxIter=80, layers=[8, 6, 6], stepSize=0.1, solver='gd'\n",
    "# RMSE on Validation Set: 1.955525563079031\n",
    "# MAE on Validation Set: 1.2077877931603328\n",
    "# ^ Exp with solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44Y5SBL4aUJ_"
   },
   "outputs": [],
   "source": [
    "#retrain network with optimal parameters on the train set\n",
    "#test network on test set\n",
    "\n",
    "layers = [8, 12, 6]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=40, layers=layers, \n",
    "                                         blockSize=128, seed=1234, \n",
    "                                         labelCol='stars', stepSize=0.1)\n",
    "\n",
    "# train the model with full train set\n",
    "model = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = result.select(\"prediction\", \"stars\")\n",
    "result.unpersist()\n",
    "\n",
    "evlauator_rmse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"rmse\")\n",
    "rmse = evlauator_rmse.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"RMSE on Test Set: \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using only RMSE for validation\n",
    "evlauator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"stars\", metricName=\"mae\")\n",
    "mae = evlauator_mae.evaluate(predictionAndLabels)\n",
    "\n",
    "print(\"MAE on Test Set: \"+str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxIter=40, layers=[8, 12, 6], stepSize=0.1, solver='l-bfgs'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6bm13S4aJozdXBMStgeJJ",
   "collapsed_sections": [],
   "name": "YelpRatings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
